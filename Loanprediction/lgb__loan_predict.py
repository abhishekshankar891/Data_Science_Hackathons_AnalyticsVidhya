# -*- coding: utf-8 -*-
"""LGB_ Loan_Predict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/153tGvxQj1U-shYlbOsXUukvjxCmwGX_L
"""

import google.colab  as colab
from google.colab import drive
drive.mount('/content/drive')

cd /content/drive/My Drive/Sapient/

#!unzip -q "/content/drive/My Drive/Sapient/Complete-Data-Set.zip"

import pandas as pd
import pandas as pd
import numpy as np

from lightgbm import LGBMClassifier
from sklearn.metrics import roc_auc_score, roc_curve
from sklearn.model_selection import KFold, StratifiedKFold
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn import preprocessing
import sklearn
import seaborn as sns
from seaborn import countplot
from matplotlib.pyplot import figure, show

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import KFold

train_df=pd.read_csv("application_train.csv")
test_df=pd.read_csv('application_test.csv')

train_df.fillna(-999,inplace=True)
test_df.fillna(-999,inplace=True)


data=train_df

data['CODE_GENDER']=data['CODE_GENDER'].replace("XNA",-999)
test_df['CODE_GENDER']=test_df['CODE_GENDER'].replace("XNA",-999)

data['Age']=data['DAYS_BIRTH']/365*(-1)
test_df['Age']=test_df['DAYS_BIRTH']/365*(-1)

data['credittoAnnuityratio']=data['AMT_CREDIT']/data['AMT_ANNUITY']
test_df['credittoAnnuityratio']=test_df['AMT_CREDIT']/test_df['AMT_ANNUITY']

data['credittogoodsprice']=data['AMT_CREDIT']/data['AMT_GOODS_PRICE']
test_df['credittogoodsprice']=test_df['AMT_CREDIT']/test_df['AMT_GOODS_PRICE']

education_mapper = {'Lower secondary':1, 
                'Secondary / secondary special':2,
                'Incomplete higher':2,'Higher education':3,'Academic degree':4
                   }

test_df['EDUCATION_TYPE']=test_df['NAME_EDUCATION_TYPE'].replace(education_mapper)
data['EDUCATION_TYPE']=data['NAME_EDUCATION_TYPE'].replace(education_mapper)

data.drop(['AMT_CREDIT','AMT_ANNUITY','DAYS_BIRTH','NAME_EDUCATION_TYPE'],axis=1,inplace=True)
test_df.drop(['AMT_CREDIT','AMT_ANNUITY','DAYS_BIRTH','NAME_EDUCATION_TYPE',],axis=1,inplace=True)



data['credittoAnnuityratio'].describe()

test_df.shape

from google.colab import files
df=data.select_dtypes(exclude='object')
fig=train_df.hist(bins=15, figsize=(50, 300), layout=(130, 15));
plt.savefig("hist.png")
files.download("hist.png")

data['DAYS_EMPLOYED']=data['DAYS_EMPLOYED'].replace(365243,-999)
test_df['DAYS_EMPLOYED']=test_df['DAYS_EMPLOYED'].replace(365243,-999)

# Correlation Matrix Heatmap

f, ax = plt.subplots(figsize=(100,50))
corr = data.corr()
hm = sns.heatmap(round(corr,2), annot=True, ax=ax, cmap="coolwarm",fmt='.2f',
                 linewidths=.05)
f.subplots_adjust(top=0.93)
t= f.suptitle('Loan Attributes Correlation Heatmap', fontsize=14)
plt.savefig("Correlation.png")
files.download("Correlation.png")

plt.figure(figsize=(30,30))
sns_plot=sns.heatmap(df.corr());
sns_plot.figure.savefig("correl.jpg")

from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
import lightgbm as lgb

train = pd.get_dummies(data)
test = pd.get_dummies(test_df)
print('Training  size: ',train.shape)
print('Testing size: ', test.shape)

#train_df= train.drop(['TARGET','SK_ID_CURR'],axis=1)
#y = train.TARGET
#test=test.iloc[:,1:]

def display_importances(feature_importance_df_):
    cols = feature_importance_df_[["feature", "importance"]].groupby("feature").mean().sort_values(by="importance", ascending=False)[:40].index
    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]
    plt.figure(figsize=(8, 10))
    sns.barplot(x="importance", y="feature", data=best_features.sort_values(by="importance", ascending=False))
    plt.title('LightGBM Features (avg over folds)')
    plt.tight_layout()
    plt.savefig('lgbm_importances.png')

import gc
from google.colab import files
submission = pd.read_csv("sample_submission.csv")
def kfold_lightgbm(df1,df2, num_folds, stratified = False, debug= False):

    # Divide in training/validation and test data
    train_df = df1
    test_df = df2
    print("Starting LightGBM. Train shape: {}, test shape: {}".format(train_df.shape, test_df.shape))
    del df1
    del df2
    gc.collect()
    # Cross validation model
    if stratified:
        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1001)
    else:
        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)
    # Create arrays and dataframes to store results
    oof_preds = np.zeros(train_df.shape[0])
    sub_preds = np.zeros(test_df.shape[0])
    feature_importance_df = pd.DataFrame()
    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]
    
    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):
        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]
        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]

        
        clf = LGBMClassifier(
            nthread=4,
            n_estimators=10000,
            learning_rate=0.01,
            num_leaves=34,
            colsample_bytree=0.9497036,
            subsample=0.8715623,
            max_depth=8,
            reg_alpha=0.041545473,
            reg_lambda=0.0735294,
            min_split_gain=0.0222415,
            min_child_weight=39.3259775,
            silent=-1,
            verbose=-1, )

        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], 
            eval_metric= 'auc', verbose= 200, early_stopping_rounds= 100)

        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]
        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1]/ folds.n_splits

        fold_importance_df = pd.DataFrame()
        fold_importance_df["feature"] = feats
        fold_importance_df["importance"] = clf.feature_importances_
        fold_importance_df["fold"] = n_fold + 1
        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)
        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))
        del clf, train_x, train_y, valid_x, valid_y
        gc.collect()

    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))
    
   
    
    if not debug:
       preds =np.where(sub_preds > 0.5, 1, 0)
       test_df['TARGET'] = preds
       Submission=test_df[['SK_ID_CURR', 'TARGET']].to_csv(submission_file_name, index= False)
       
   
    display_importances(feature_importance_df)
    return feature_importance_df

def main(debug = False):
  
 xx= kfold_lightgbm(train,test,5, False,False)

if __name__ == "__main__":
    submission_file_name = "submission_1.csv"
    
    main()